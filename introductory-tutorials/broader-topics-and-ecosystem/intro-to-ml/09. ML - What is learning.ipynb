{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## What is learning?\n\nComputers read data, as we saw in notebooks 1 and 2. We can then build functions that model that data to make decisions, as we saw in notebooks 3 and 5. \n\nBut how do you make sure that the model actually fits the data well? In the last notebook, we saw that we can fiddle with the parameters of our function defining the model to reduce the loss function. However, we don't want to have to pick the model parameters ourselves. Choosing parameters ourselves works *well enough* when we have a simple model and only a few data points, but can quickly become extremely complex for more detailed models and larger data sets. \n\nInstead, we want our machine to *learn* the parameters that fit the model to our data, without needing us to fiddle with the parameters ourselves. In this notebook, we'll talk about the \"learning\" in machine learning."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Motivation: Fitting parameters by hand\n\nLet's go back to our example of fitting parameters from notebook 3. Recall that we looked at whether the amount of green in the pictures could distinguish between an apple and a banana, and used a sigmoid function to model our choice of \"apple or banana\" using the amount of green in an image."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Plots; gr()\nusing Images; using Interact\n\nσ(x,w,b) = 1 / (1 + exp(-w*x+b))\n\napple =  load(\"data/10_100.jpg\")\nbanana = load(\"data/104_100.jpg\")\napple_green_amount =  mean(Float64.(green.(apple)))\nbanana_green_amount = mean(Float64.(green.(banana)));\n\n@manipulate for w in -10:0.01:30, b in 0:0.1:30\n    \n    plot(x->σ(x,w,b), 0, 1, label=\"Model\", legend = :topleft, lw=3)\n    scatter!([apple_green_amount],  [0.0], label=\"Apple\")\n    scatter!([banana_green_amount], [1.0], label=\"Banana\")\n    \nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intuitively, how did you tweak the sliders so that way the model sends apples to 0 and bananas to 1? Most likely, you did the following:\n\n#### Move the sliders a bit, see whether the curve moves in the right direction, and if it did, keep doing it.\n\nFor a machine, \"learning\" is that same process, translated into math!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \"Learning by nudging\": The process of descent\n\nLet's start to formalize this idea. In order to push the curve in the \"right direction\", we need some measurement of \"how right\" and \"how wrong\" the model is. When we translate the idea of a \"right direction\" into math, we end up with a **loss function**, `L(w, b)`, as we saw in notebook 5. We say that the loss function is lowest when the model `σ(x, w, b)` performs the best. \n\nNow we want to create a loss function that is the lowest when the apple is at `0` and the banana is at `1`. If the data (the amount of green) for our apple is $x_1$, then our model will output $σ(x_1,w, b)$ for our apple. So, we want the difference $0 - σ(x_1, w, b)$ to be small. Similarly, if our data for our banana (the banana's amount of green) is $x_2$, we want the difference $1 - σ(x_2, w, b)$ to be small.\n\nTo create our loss function, let's add together the squares of the difference of the model's output from the desired output for the apple and the banana. We get\n\n$$ L(w,b) = (0 - σ(x_1, w, b))^2 + (1 - σ(x_2, w, b))^2. $$\n\n$L(w, b)$ is lowest when it outputs `0` for the apple and `1` for the banana, and thus the cost is lowest when the model \"is correct\".\n\nWe can visualize this function by plotting it in 3D with the `surface` function."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "# plotly()\ngr()"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "L(w, b) = (0 - σ(apple_green_amount,w,b))^2 + (1 - σ(banana_green_amount,w,b))^2\n\nw_range = 10:0.1:13\nb_range = 0:1:20\n\nL_values = [L(w,b) for b in b_range, w in w_range]\n\n\n@manipulate for w in w_range, b in b_range\n    p1 = surface(w_range, b_range, L_values, xlabel=\"w\", ylabel=\"b\", cam=(70,40), cbar=false, leg=false)\n    scatter!(p1, [w], [b], [L(w,b)+1e-2], markersize=5, color = :blue)\n    p2 = plot(x->σ(x,w,b), 0, 1, label=\"Model\", legend = :topleft, lw=3)\n    scatter!(p2, [apple_green_amount],  [0.0], label=\"Apple\", markersize=10)\n    scatter!(p2, [banana_green_amount], [1.0], label=\"Banana\", markersize=10, xlim=(0,1), ylim=(0,1))\n    plot(p1, p2, layout=(2,1))\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The blue ball on the 3D plot shows the current parameter choices, plotted as `(w,b)`. Shown below the 3D plot is a 2D plot of the corresponding model with those parameters. Notice that as the blue ball rolls down the hill, the model becomes a better fit. Our loss function gives us a mathematical notion of a \"hill\", and the process of \"learning by nudging\" is simply rolling the ball down that hill."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "To do this mathematically, we need to know which direction is \"downhill\". Recall from calculus that the derivative of `L` with respect to `b` tells you how `L` changes when `b` changes. Thus to roll downhill, we should go in the direction where the derivative is negative (the function goes down) for each parameter. This direction is the negative of what's called the **gradient**, $\\nabla L$. This means that the \"learn by nudging method\" can be rephrased in mathematical terms as:\n\n1. Calculate the gradient\n2. Move a little bit in the direction of the negative gradient\n3. Repeat\n\nThis process of rolling the ball in the direction of the negative gradient is called **gradient descent**; written mathematically, it is\n\n$$p_{n+1} = p_n - \\eta \\nabla L(p_n).$$\n\nHere, $p_n$ represents the vector of current parameters $(w, b)$; $\\nabla L(p_n)$ is the gradient of the loss function, given those parameters. We start from $p_n$ and change it by $\\eta \\nabla L(p_n)$, where $\\eta$ is a small step size that determines how far we move the parameters in the direction of the negative gradient; notice that if you step too far, you'll overshoot the minimum!. The result is $p_{n+1}$, the new vector of parameters.\n\n[Picture of Gradient Descent Vectors]\n\nIf we repeat this process, then we will end up at parameters where the model correctly labels apples as `0` and bananas as `1`. When this happens, the model has learned from the data and can then read pictures and tell you whether they are apples or bananas!"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise 1\n\nUse the following terms to fill in the sentences below. Terms may be used more than once or not at all:\n> gradient, loss function, derivative, gradient descent, learning.\n\n* We can think of a _(A)_ as a 1D version of a _(B)_.\n* We can visualize a _(C)_ as a hill.\n* In the explanation above, rolling downhill is called _(D)_ and means traveling along the _(E)_.\n* To quantify the correctness of a model we use a _(F)_.\n* When our program can minimize a _(G)_ on its own, we say it is _(H)_.\n\n<br><br>\n\nA)<br>\nB)<br>\nC)<br>\nD)<br>\nE)<br>\nF)<br>\nG)<br>\nH)<br>"
      ],
      "metadata": {}
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "0.6.2"
    },
    "kernelspec": {
      "name": "julia-0.6",
      "display_name": "Julia 0.6.2",
      "language": "julia"
    }
  },
  "nbformat": 4
}
